import os
import shutil
from dotenv import load_dotenv
from functions import load_documents, split_documents, filter_complex_metadata
from constants import DB_PATHS, LECTURE_MODES, EMBEDDING_MODEL

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ï¼ˆç‰¹ã«OPENAI_API_KEYï¼‰
load_dotenv()

# LangChainã®å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
import chromadb

def create_all_databases():
    """
    ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã™ã¹ã¦ã®è¬›æ¼”ãƒ¢ãƒ¼ãƒ‰ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã¾ãŸã¯å†ä½œæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
    """
    print("Starting database creation process...")

    # OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ Error: OPENAI_API_KEY environment variable not set.")
        print("Please create a .env file and add your OpenAI API key to it.")
        return

    # ã™ã¹ã¦ã®è¬›æ¼”ãƒ¢ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ãƒ«ãƒ¼ãƒ—å‡¦ç†
    for mode, title in LECTURE_MODES.items():
        print(f"\n--- Processing mode: '{mode}' ({title}) ---")
        db_path = DB_PATHS.get(mode)

        if not db_path:
            print(f"âš ï¸ Warning: DB path for mode '{mode}' not defined. Skipping.")
            continue

        # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒã‚ã‚Œã°ä¸€åº¦å‰Šé™¤ã™ã‚‹
        if os.path.exists(db_path):
            print(f"ğŸ—‘ï¸ Found existing database at {db_path}. Removing it.")
            try:
                shutil.rmtree(db_path)
                print(f"âœ… Successfully removed old database.")
            except OSError as e:
                print(f"âŒ Error removing database at {db_path}: {e}")
                continue # æ¬¡ã®ãƒ¢ãƒ¼ãƒ‰ã¸

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(db_path, exist_ok=True)

        # 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿
        print("ğŸ“„ Loading documents...")
        documents = load_documents(mode)
        if not documents:
            print(f"âŒ FAILURE - No documents were loaded for mode '{mode}'. Check file paths in constants.py.")
            continue
        print(f"ğŸ‘ Loaded {len(documents)} documents.")

        # 2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²
        print("ğŸ”ª Splitting documents into chunks...")
        chunks = split_documents(documents)
        if not chunks:
            print(f"âŒ FAILURE - Document splitting for mode '{mode}' resulted in 0 chunks.")
            continue
        print(f"ğŸ‘ Split into {len(chunks)} chunks.")

        # 3. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        print("ğŸ§¹ Filtering complex metadata from chunks...")
        filtered_chunks = filter_complex_metadata(chunks)
        if not filtered_chunks:
            print(f"âŒ FAILURE - All chunks were filtered out for mode '{mode}'.")
            continue
        print(f"ğŸ‘ Filtered chunks remain: {len(filtered_chunks)}.")

        # 4. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆã¨æ°¸ç¶šåŒ–
        print("ğŸ§  Creating and persisting vector store...")
        try:
            embedding_function = OpenAIEmbeddings(model=EMBEDDING_MODEL)
            
            # ChromaDBã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
            client = chromadb.PersistentClient(path=db_path)

            # ChromaDBã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æŠ•å…¥ã—ã€æ°¸ç¶šåŒ–ã™ã‚‹
            Chroma.from_documents(
                documents=filtered_chunks, 
                embedding=embedding_function,
                client=client,
                collection_name=f"collection_{mode}" # å®‰å®šç‰ˆã®APIã§ã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚‚æŒ‡å®šæ¨å¥¨
            )
            
            print(f"âœ… Vector store for '{mode}' created and persisted at {db_path}")

        except Exception as e:
            print(f"âŒ An error occurred during vector store creation: {e}")
            import traceback
            print(traceback.format_exc())

    print("\n--- Database creation process finished. ---")

if __name__ == "__main__":
    # ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«ã®ã¿ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆå‡¦ç†ã‚’å‘¼ã³å‡ºã™
    create_all_databases()
